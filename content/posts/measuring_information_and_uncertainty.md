---
title: "Measuring_information_and_uncertainty"
date: 2023-12-11T22:44:03+08:00
draft: false
---

The paper by Alexander Frankel and Emir Kamenica, featured in the *American Economic Review* in 2019, is exceptionally remarkable. Their work, titled *Quantifying Information and Uncertainty*, delves into the intricate dynamics of information and belief systems.

> Reference: *Quantifying Information and Uncertainty (2019)* by Alexander Frankel and Emir Kamenica. Published in the *American Economic Review*, Volume 109, Issue 10, pages 3650â€“3680. [DOI: 10.1257/aer.20181897](https://doi.org/10.1257/aer.20181897).

Suppose we observe some pieces of news. How might we quantify the amount of information contained in it? Another related question, how might we quantify the uncertainty of a belief? One desideratum might be that the measure of information/uncertainty should correspond to the instrumental value/loss associated with *some* decision problem.

Let's get down to business. Consider a finite state space $\Omega = \{1, 2, ..., n\}$, with a typical state denoted as $\omega \in \Omega$. A belief $q$ is distribution on $\Omega$ that puts weight $q^\omega$ on state $\omega$. For a believe that is degenerate on $\omega$, denote $\delta_\omega$.

Information is generated by signals. Let $S$ be the set of non-empty Lebesgue-measurable subsets $\Omega \times [0, 1]$, then, $\pi \subset S$ is a signal and some $s\in \pi$ would be the realization of the signal. Intuitively, for state $\omega$, a random variable $x$ WLOG drawn uniformly from $[0, 1]$ determines the signal realization conditional on the state, where the probability of observing realization of signal $s\in \pi$ in state $w$ is the Lebesgue measure of $\{x \in [0, 1]|(\omega, x)\in s\}$.

Usually, we write $\alpha$ as the realized random variable induced by signal $\pi_\alpha$. Given prior $q$, denote the posterior induced by signal realization $\alpha$ by $q(\alpha)$.

Join us tomorrow for Part II of our exploration.
