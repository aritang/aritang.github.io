<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>TCS on ariana&#39;s blog</title>
    <link>//localhost:1313/tags/tcs/</link>
    <description>Recent content in TCS on ariana&#39;s blog</description>
    <generator>Hugo -- 0.140.2</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2024 13:57:29 -0700</lastBuildDate>
    <atom:link href="//localhost:1313/tags/tcs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>game theory, with a little help from machine learning II</title>
      <link>//localhost:1313/posts/rain_seminar_2/</link>
      <pubDate>Thu, 27 Jun 2024 13:57:29 -0700</pubDate>
      <guid>//localhost:1313/posts/rain_seminar_2/</guid>
      <description>&lt;p&gt;&lt;em&gt;Following yesterday&amp;rsquo;s post (&lt;a href=&#34;//localhost:1313/posts/RAIN_seminar_1/&#34;&gt;here&lt;/a&gt;), let&amp;rsquo;s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;regret-minimization-in-stackelberg-games-with-side-information&#34;&gt;Regret Minimization in Stackelberg Games with Side Information&lt;/h2&gt;
&lt;p&gt;Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | &lt;a href=&#34;https://arxiv.org/abs/2402.08576&#34;&gt;paper&amp;rsquo;s arxiv link&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;recap-of-the-mode&#34;&gt;recap of the mode:&lt;/h3&gt;
&lt;p&gt;A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \mathbf p \in \mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event.&lt;/p&gt;</description>
    </item>
    <item>
      <title>game theory, with a little help from machine learning I</title>
      <link>//localhost:1313/posts/rain_seminar_1/</link>
      <pubDate>Wed, 26 Jun 2024 07:26:22 -0700</pubDate>
      <guid>//localhost:1313/posts/rain_seminar_1/</guid>
      <description>&lt;p&gt;Of course, the general purpose of an academic presentation is multifaceted (see an &lt;a href=&#34;//localhost:1313/posts/idea_of_a_presentation/&#34;&gt;older post&lt;/a&gt; about it), as discussed here. Nevertheless, I&amp;rsquo;ve once heard someone say that the key purpose of a talk at a conference is to &lt;strong&gt;make your audience interested in reading your work after the talk ends&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I attended the RAIN seminar &lt;a href=&#34;posts/rain_seminar/&#34;&gt;yesterday&lt;/a&gt; at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan&amp;rsquo;s talk was particularly captivating. So, I decided to read a bit of the paper, &lt;em&gt;Online Learning in Stackelberg Security Games&lt;/em&gt; :&lt;/p&gt;</description>
    </item>
    <item>
      <title>Nina Balcan presents | Online learning in Stackelberg Security Games</title>
      <link>//localhost:1313/posts/rain_seminar/</link>
      <pubDate>Tue, 25 Jun 2024 00:15:24 -0700</pubDate>
      <guid>//localhost:1313/posts/rain_seminar/</guid>
      <description>&lt;p&gt;I had the very fortune to listen to Nina Balcan giving a talk on one of her latest work, &lt;em&gt;&lt;strong&gt;Online learning in Stackelberg Security Games&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ABSTRACT&lt;/p&gt;
&lt;p&gt;In a Stackelberg Security Game, a defender commits to a randomized deployment of security resources, and an attacker best responds by attacking a target that maximizes their utility. While algorithms for computing an optimal strategy for the defender to commit to have been used in several real-world applications, deployed applications require knowledge about the utility function of the potential attacker. In this talk I will describe an online learning approach for addressing this problem. We consider algorithms that prescribe a randomized strategy for the defender at each step against an adversarially chosen sequence of attackers and obtain feedback on their choices. I will discuss online algorithms whose regret (when compared to the best fixed strategy in hindsight) is sublinear in the number of time steps. I will also consider an extension that handles auxiliary contextual information that is often readily available to each player (e.g. traffic patterns or weather conditions) and discuss what no regret guarantees are possible in this even more realistic scenario.&lt;/p&gt;</description>
    </item>
    <item>
      <title>write-up | algorithmic classification and strategic effort</title>
      <link>//localhost:1313/posts/network_principle_agent/</link>
      <pubDate>Tue, 04 Jun 2024 23:47:17 +0800</pubDate>
      <guid>//localhost:1313/posts/network_principle_agent/</guid>
      <description>&lt;p&gt;A memoir of Market Mechanism Design course&amp;rsquo;s final presentation report, based on:&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&#34;algorithmic-classification-and-strategic-effort&#34;&gt;Algorithmic Classification and Strategic Effort&lt;/h3&gt;
&lt;p&gt;Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;motivation-difference-in-modelling-strategic-behavior-and-objectivesbetween-econcs-perspectives&#34;&gt;motivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mostly OM diary | The Limits of Personalization in Assortment Optimization</title>
      <link>//localhost:1313/posts/mostly_om_1/</link>
      <pubDate>Thu, 30 May 2024 08:40:08 +0800</pubDate>
      <guid>//localhost:1313/posts/mostly_om_1/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;speaker: &lt;strong&gt;Guillermo Gallego&lt;/strong&gt; | Prof., The Chinese University of Hong Kong-Shenzhen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;talk-abstract&#34;&gt;&lt;em&gt;&lt;strong&gt;TALK ABSTRACT&lt;/strong&gt;&lt;/em&gt;:&lt;/h2&gt;
&lt;p&gt;To study the limits of personalization, we introduce the notion of a clairvoyant firm that can read the mind of consumers and sell them the highest revenue product that they are willing to buy. We show how to compute the expected revenue of the clairvoyant firm for a class of rational discrete choice models, and develop prophet-type inequalities that provide performance guarantees for the expected revenue of the traditional assortment optimization firm (a TAOP firm) relative to the clairvoyant firm, and therefore to any effort to personalize assortments.  In particular, we show that the expected revenue of the clairvoyant firm cannot exceed twice the expected revenue of the TAOP for the RCS model, the MNL, the GAM and the Nested-Logit Model. On the other hand, there are random utility models for which personalized assortments can earn up to $n$ times more than a TAOP firm, where $n$ is the number of products. Our numerical studies indicate that when the mean utilities of the products are heterogeneous among consumer types, and the variance of the utilities is small, firms can gain substantial benefits from personalized assortments. We support these observations, and others, with theoretical findings.  While the consumers’ surplus can potentially be larger under personalized assortments, clairvoyant firms with pricing power can extract all surplus, and earn arbitrarily more than traditional firms that optimize over prices but do not personalize them. For the price-aware MNL, however, a clairvoyant firm can earn at most $\exp(1)$ more than a traditional firm.&lt;/p&gt;</description>
    </item>
    <item>
      <title>regulation for algorithmic collusion</title>
      <link>//localhost:1313/posts/regulating_algorithmic_collusion/</link>
      <pubDate>Tue, 30 Apr 2024 22:52:19 +0800</pubDate>
      <guid>//localhost:1313/posts/regulating_algorithmic_collusion/</guid>
      <description>&lt;p&gt;This week, &lt;strong&gt;Chenhao Zhang&lt;/strong&gt; from Northwestern University visited ITCS and gave &lt;a href=&#34;https://itcs.sufe.edu.cn/48/71/c10453a215153/page.htm&#34;&gt;a talk on Regulation of Algorithmic Collusion&lt;/a&gt;, based on his ongoing collaboration with Prof. Jason Hartline. Here&amp;rsquo;s a background of the topic, summary of the talk and their work (hopefully), and some discussion afterwards.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&#34;regulation-of-algorithmic-collusion&#34;&gt;Regulation of Algorithmic Collusion&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ABSTRACT&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Consider sellers in a competitive market that use algorithms to adapt their prices from data that they collect. In such a context it is plausible that algorithms could arrive at prices that are higher than the competitive prices and this may benefit sellers at the expense of consumers (i.e., the buyers in the market). This paper gives a definition of plausible algorithmic non-collusion for pricing algorithms. The definition allows a regulator to empirically audit algorithms by applying a statistical test to the data that they collect. Algorithms that are good, i.e., approximately optimize prices to market conditions, can be augmented to contain the data sufficient to pass the audit. Algorithms that have colluded on, e.g., supra-competitive prices cannot pass the audit. The definition allows sellers to possess useful side information that may be correlated with supply and demand and could affect the prices used by good algorithms. The paper provides an analysis of the statistical complexity of such an audit, i.e., how much data is sufficient for the test of non-collusion to be accurate.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
