<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>game theory, with a little help from machine learning II | ariana&#39;s blog</title>
<meta name="keywords" content="paper, TCS">
<meta name="description" content="Following yesterday&rsquo;s post (here), let&rsquo;s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.

Regret Minimization in Stackelberg Games with Side Information
Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | paper&rsquo;s arxiv link

recap of the mode:
A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \mathbf p \in \mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event.">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/posts/rain_seminar_2/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/posts/rain_seminar_2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>




<meta property="og:title" content="game theory, with a little help from machine learning II" />
<meta property="og:description" content="Following yesterday&rsquo;s post (here), let&rsquo;s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.

Regret Minimization in Stackelberg Games with Side Information
Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | paper&rsquo;s arxiv link

recap of the mode:
A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \mathbf p \in \mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event." />
<meta property="og:type" content="article" />
<meta property="og:url" content="//localhost:1313/posts/rain_seminar_2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-06-27T13:57:29-07:00" />
<meta property="article:modified_time" content="2024-06-27T13:57:29-07:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="game theory, with a little help from machine learning II"/>
<meta name="twitter:description" content="Following yesterday&rsquo;s post (here), let&rsquo;s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.

Regret Minimization in Stackelberg Games with Side Information
Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | paper&rsquo;s arxiv link

recap of the mode:
A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \mathbf p \in \mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "//localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "game theory, with a little help from machine learning II",
      "item": "//localhost:1313/posts/rain_seminar_2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "game theory, with a little help from machine learning II",
  "name": "game theory, with a little help from machine learning II",
  "description": "Following yesterday\u0026rsquo;s post (here), let\u0026rsquo;s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.\nRegret Minimization in Stackelberg Games with Side Information Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | paper\u0026rsquo;s arxiv link\nrecap of the mode: A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \\mathbf p \\in \\mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event.\n",
  "keywords": [
    "paper", "TCS"
  ],
  "articleBody": "Following yesterday’s post (here), let’s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.\nRegret Minimization in Stackelberg Games with Side Information Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | paper’s arxiv link\nrecap of the mode: A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \\mathbf p \\in \\mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event.\nThe attacker seeks to maximize utility given the defender’s strategy: $$ \\text{(attacker’s utility) } U^\\text a(\\mathbf p) := \\max_{\\mathbf y} \\sum_{i\\in [n]}y_i\\left( p_iu^1_i + (1 - p_i)u^0_i\\right) $$ The defender’s utility, given the attacker’s best response $ \\mathbf y^(\\mathbf p) $, is: $$ \\text{(defender’s utility) } U^\\text d (\\mathbf p) = \\sum_{i \\in [n]} \\left( y^_i (v^1_i p_i + v^0_i (1 - p_i)) + (1 - y^*_i)(\\bar v_i^1 p_i + \\bar v_i (1 - p_i)) \\right) $$\nregret is defined as: $$ \\text{(regret) }R(T) = \\tilde U^d(\\mathbf {\\tilde {p^t}})-\\sum_{t = 1}^T U^d(\\mathbf p^t) $$ where $ \\tilde U^d $ is the optimal-in-hindsight benchmark.\ncontextual attackers In each round $ t \\in [T] $, nature reveals a context $ \\mathbf z_t \\in \\mathcal{Z} \\subset \\mathbb{R}^d $ to both players.\nFor example, in airport security, $ \\mathbf z_t $ might include arrival and departure times, passenger counts, and valuable cargo information. In cyber-defense, it might be network traffic statistics.\nBoth players’ utilities depend on the context: $$ U_a(\\text{or } U^d) : \\mathcal{Z} \\times \\text{Action Space} \\to \\mathbb{R} $$ Given the sequence of attackers $ {A_{k_1}, \\ldots, A_{k_T}} $ and context $ \\mathbf z_1, \\ldots, \\mathbf z_T $, the optimal-in-hindsight policy for context $ \\mathbf z $ is:\n$$\\pi^{*}(\\mathbf z) \\in \\arg\\max_{\\mathbf p} \\sum_{t = 1}^T U(\\mathbf {z}, \\mathbf p, \\mathbf y (\\mathbf p, \\mathbf z)) \\mathbb{1}{\\mathbf z_t = \\mathbf z}.$$\nContextual regret is then defined as: $$ R(T) := \\sum_{t = 1}^T \\left( U(\\mathbf z, {\\pi}(\\mathbf z), \\mathbf y(\\pi{}(\\mathbf z), \\mathbf z)) \\mathbb{1}{\\mathbf z_t = \\mathbf z} - U^{\\text{opt}} \\right) $$\nintuition and result The paper begins by demonstrating the impossibility of no-regret learning in a fully adversarial setting where both contexts and attackers are chosen adversarially.\nMotivated by this result, the authors explore two natural relaxations: the settings in which either the sequence of followers is chosen stochastically or the sequence of contexts is stochastic:\nHarris et al., 2024\nreflections: Although I haven’t fully read the technicals of the paper yet, for the paper itself, an interesting thing to point out is how the authors defined optimal-in-hindsight benchmark. Just to motivate the nuance of the definition: despite the sequence of attackers being given, attacker’s target changes when $\\mathbf p$ changes. This adds an additional layer of complexity (hence, flexibility) to the problem and makes the model more versatile and interesting (according to another friend that I’ve talk to during the seminar).\nAs for online problems in general, for me personally, different kinds of online problems and their associated methodologies and mathematical tools has been quite enlightening yet overwhelming. These include Bandits with MWU, Restless Multi-Armed Bandits with Whittle Index, Prophet Inequality, Online Linear Programming, and the dual-threshold descent method, among others.\nOnline problems are inherently dynamic, which makes them challenging from the start. And, their analysis often involves intimidating, advanced mathematical tools. It requires both intuition and high-level math skills.\nI feel anxious about mastering these concepts, but I’m also looking forward to the online problem seminar course next semester. Hopefully, it will provide more clarity and boost my skill in tackling these intricate things.\n",
  "wordCount" : "619",
  "inLanguage": "en",
  "datePublished": "2024-06-27T13:57:29-07:00",
  "dateModified": "2024-06-27T13:57:29-07:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//localhost:1313/posts/rain_seminar_2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "ariana's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "//localhost:1313/favicon.ico"
    }
  }
}
</script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Product+Sans:wght@400;700&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="//localhost:1313/css/custom.b017fc6c61ff4eacd2943e3c9726e1a935c706d1ea1a1b7c17773e63b47342d3.css">
    
<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053">
</script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

<script>
  gtag('event', 'conversion', {
      'send_to': 'AW-16651897053/wjItCK3FisUZEN2Rn4Q-',
      'value': 1.0,
      'currency': 'USD'
  });
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/" accesskey="h" title="ariana&#39;s blog (Alt + H)">ariana&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/search" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/archives" title="archive">
                    <span>archive</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/tags" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/pinned" title="about me">
                    <span>about me</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/procrastination_bulletin" title="pending ideas">
                    <span>pending ideas</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      game theory, with a little help from machine learning II
    </h1>
    <div class="post-meta">&lt;span title=&#39;2024-06-27 13:57:29 -0700 -0700&#39;&gt;June 27, 2024&lt;/span&gt;

</div>
  </header>
  <div class="post-content"><p><em>Following yesterday&rsquo;s post (<a href="/posts/RAIN_seminar_1/">here</a>), let&rsquo;s delve deeper into Stackelberg Games and the key points of the paper, particularly the addition of context to the problem setting.</em></p>
<blockquote>
<h2 id="regret-minimization-in-stackelberg-games-with-side-information">Regret Minimization in Stackelberg Games with Side Information<a hidden class="anchor" aria-hidden="true" href="#regret-minimization-in-stackelberg-games-with-side-information">#</a></h2>
<p>Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | <a href="https://arxiv.org/abs/2402.08576">paper&rsquo;s arxiv link</a></p>
</blockquote>
<h3 id="recap-of-the-mode">recap of the mode:<a hidden class="anchor" aria-hidden="true" href="#recap-of-the-mode">#</a></h3>
<p>A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a strategy $ \mathbf p \in \mathbb{R}^n $ over $ n $ targets, and the attacker selects a target. The utility outcome for both parties depends on their actions and possibly some unknown world state event.</p>
<p>The attacker seeks to maximize utility given the defender&rsquo;s strategy:
$$
\text{(attacker&rsquo;s utility) } U^\text a(\mathbf p) :=  \max_{\mathbf y} \sum_{i\in [n]}y_i\left(  p_iu^1_i + (1 - p_i)u^0_i\right)
$$
The defender&rsquo;s utility, given the attacker&rsquo;s best response $ \mathbf y^<em>(\mathbf p) $, is:
$$
\text{(defender&rsquo;s utility) } U^\text d (\mathbf p) =  \sum_{i \in [n]} \left( y^</em>_i (v^1_i p_i + v^0_i (1 - p_i)) + (1 - y^*_i)(\bar v_i^1 p_i + \bar v_i (1 - p_i)) \right)
$$</p>
<p>regret is defined as:
$$
\text{(regret) }R(T) =  \tilde U^d(\mathbf {\tilde {p^t}})-\sum_{t = 1}^T U^d(\mathbf p^t)
$$
where $ \tilde U^d $ is the optimal-in-hindsight benchmark.</p>
<h3 id="contextual-attackers">contextual attackers<a hidden class="anchor" aria-hidden="true" href="#contextual-attackers">#</a></h3>
<p>In each round $ t \in [T] $, nature reveals a context $ \mathbf z_t \in \mathcal{Z} \subset \mathbb{R}^d $ to both players.</p>
<blockquote>
<p>For example, in airport security, $ \mathbf z_t $ might include arrival and departure times, passenger counts, and valuable cargo information. In cyber-defense, it might be network traffic statistics.</p>
</blockquote>
<p>Both players&rsquo; utilities depend on the context:
$$
U_a(\text{or } U^d) : \mathcal{Z} \times \text{Action Space} \to \mathbb{R}
$$
Given the sequence of attackers $ {A_{k_1}, \ldots, A_{k_T}} $ and context $ \mathbf z_1, \ldots, \mathbf z_T $, the optimal-in-hindsight policy for context $ \mathbf z $ is:</p>
<p>$$\pi^{*}(\mathbf z) \in \arg\max_{\mathbf p} \sum_{t = 1}^T U(\mathbf {z}, \mathbf p, \mathbf y (\mathbf p, \mathbf z)) \mathbb{1}{\mathbf z_t = \mathbf z}.$$</p>
<p>Contextual regret is then defined as:
$$
R(T) := \sum_{t = 1}^T \left( U(\mathbf z, {\pi}(\mathbf z), \mathbf y(\pi{}(\mathbf z), \mathbf z)) \mathbb{1}{\mathbf z_t = \mathbf z} - U^{\text{opt}} \right)
$$</p>
<h3 id="intuition-and-result">intuition and result<a hidden class="anchor" aria-hidden="true" href="#intuition-and-result">#</a></h3>
<p>The paper begins by demonstrating the impossibility of no-regret learning in a fully adversarial setting where both contexts and attackers are chosen adversarially.</p>
<p>Motivated by this result, the authors explore two natural relaxations: the settings in which either the sequence of followers is chosen stochastically or the sequence of contexts is stochastic:</p>
<figure class="align-center ">
    <img loading="lazy" src="/maguerite/RAIN_result.jpeg#center"
         alt="Harris et al., 2024"/> <figcaption>
            <p>Harris et al., 2024</p>
        </figcaption>
</figure>

<h3 id="reflections">reflections:<a hidden class="anchor" aria-hidden="true" href="#reflections">#</a></h3>
<p>Although I haven&rsquo;t fully read the technicals of the paper yet, for the paper itself, an interesting thing to point out is how the authors defined <strong>optimal-in-hindsight benchmark</strong>. Just to motivate the nuance of the definition: despite the sequence of attackers being given, attacker&rsquo;s target changes when $\mathbf p$ changes. This adds an additional layer of complexity (hence, flexibility) to the problem and makes the model more versatile and interesting (according to another friend that I&rsquo;ve talk to during the seminar).</p>
<p>As for online problems in general, for me personally, different kinds of online problems and their associated methodologies and mathematical tools has been quite enlightening yet overwhelming. These include Bandits with MWU, Restless Multi-Armed Bandits with Whittle Index, Prophet Inequality, Online Linear Programming, and the dual-threshold descent method, among others.</p>
<p>Online problems are inherently dynamic, which makes them challenging from the start. And, their analysis often involves intimidating, advanced mathematical tools. It requires both intuition and high-level math skills.</p>
<p>I feel anxious about mastering these concepts, but I&rsquo;m also looking forward to the online problem seminar course next semester. Hopefully, it will provide more clarity and boost my skill in tackling these intricate things.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/tags/paper/">Paper</a></li>
      <li><a href="//localhost:1313/tags/tcs/">TCS</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="//localhost:1313/">ariana&#39;s blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script id="usercentrics-cmp" src="https://web.cmp.usercentrics.eu/ui/loader.js" data-settings-id="_KlbvhaKistzRA" async></script>

</body>

</html>
