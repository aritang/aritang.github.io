<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>write-up | algorithmic classification and strategic effort | ariana&#39;s blog</title>
<meta name="keywords" content="paper, TCS">
<meta name="description" content="A memoir of Market Mechanism Design course&rsquo;s final presentation report, based on:

Algorithmic Classification and Strategic Effort
Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60

motivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives

The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/posts/network_principle_agent/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/posts/network_principle_agent/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>




<meta property="og:url" content="//localhost:1313/posts/network_principle_agent/">
  <meta property="og:site_name" content="ariana&#39;s blog">
  <meta property="og:title" content="write-up | algorithmic classification and strategic effort">
  <meta property="og:description" content="A memoir of Market Mechanism Design course’s final presentation report, based on:
Algorithmic Classification and Strategic Effort Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60
motivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-04T23:47:17+08:00">
    <meta property="article:modified_time" content="2024-06-04T23:47:17+08:00">
    <meta property="article:tag" content="Paper">
    <meta property="article:tag" content="TCS">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="write-up | algorithmic classification and strategic effort">
<meta name="twitter:description" content="A memoir of Market Mechanism Design course&rsquo;s final presentation report, based on:

Algorithmic Classification and Strategic Effort
Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60

motivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives

The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "//localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "write-up | algorithmic classification and strategic effort",
      "item": "//localhost:1313/posts/network_principle_agent/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "write-up | algorithmic classification and strategic effort",
  "name": "write-up | algorithmic classification and strategic effort",
  "description": "A memoir of Market Mechanism Design course\u0026rsquo;s final presentation report, based on:\nAlgorithmic Classification and Strategic Effort Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60\nmotivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?\n",
  "keywords": [
    "paper", "TCS"
  ],
  "articleBody": "A memoir of Market Mechanism Design course’s final presentation report, based on:\nAlgorithmic Classification and Strategic Effort Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60\nmotivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?\nThe paper proposes a model that applies ideas from principal-agent theory to the algorithmic decision-making setting.\nA key feature of models of strategic behavior in both the principal-agent and strategic classification literatures is that of hidden actions: decision-makers can’t observe the exact actions taken by a decision-subject.\nIn the principal-agent literature, this is typically captured through stochastic outcomes, where each action by the agent produces a distribution over possible outcomes, but only one outcome is realized and observed by the principal.\nIn the strategic classification literature, actions are typically not explicitly modeled; instead, a decision-maker simply observes a fea- ture vector, where the values of the feature vector can be strategically manipulated (to a limited degree) by the decision subject.\nmodel The principle has preferences over the underlying behaviors taken by decision subjects. The model requires decisions (of principle) to be made based on observable feature vectors–that he structure his mechanism to incentivize agents take certain behaviors over others.\nAlgorithmic aspect comes in when the paper models the relationship between actions and observations as an effort graph, shown in below.\neffort variables $x_1, \\ldots, x_m$, which are the $m$ actions the agent can take. features $F_1, \\ldots, F_n$ is the $n$-dimensional feature vector the decision maker actually observes.\nIn particular, each edge between $x_j$ and $F_i$ contains a parameter $\\alpha_{ji}$ indicating the degree to which action $j$ increases feature $i$. Formally $$ F_i = f_i \\left (\\sum_{j = 1}^m \\alpha_{ij} x_j \\right) $$ where $f$ is some continuous concave function, and assumed that $\\alpha \\ge 0$. Basically, the larger $\\alpha_{ij}$, the more extent of $x_j$ in increasing $F_i$.\nAssume that the model’s structure and parameters are public knowledge.\nThe mechanism designer (i.e. us, or the principle) designs a score function $H = M(\\mathbf F)$, and the agent reacts accordingly $$ \\begin{align}\\text{agent’s obj: }\\max_x \\ \u0026 M(\\mathbf F)\\cr s.t.\\ \u0026 \\sum_{j = 1}^m x_j \\le B \u0026 (\\forall i)\\cr \u0026 x_j \\ge 0 \u0026 (\\forall j) \\end{align} $$ As the designer, we are insterested in whether a particular action (i.e. effort invested) $x^* \\in \\mathbb{R}{}_{\\ge 0}^m$ (or, its support $S(x^*)$) is incentivizable via some scoring rule design of $M(\\cdot)$. The result is:\nlinear mechanisms are optimal in the following sense: whenever a ‘reasonable’ mechanism can incentivize a particular behavior, there is a linear mechanism that can do so as well.\nMoreover, let’s say, we’d like to optimize for a set of desirable actions $D\\subset [m]$. Let $\\mathcal X_D = {x | S(x) \\subset D}$ (i.e. the set of effort profiles that is only supported on $D$, that we wish to incentivize). $$ \\begin{align}\\text{principle’s obj: }\\max_x \\ \u0026 g(x) \\quad s.t.\\ x \\text{ is incentivizable} \\end{align} $$ it can be hard to incentivize a complex set of behaviors while also optimizing other objectives.\nreference Jon Kleinberg and Manish Raghavan. 2020. Algorithmic classification and strategic effort. SIGecom Exch. 18, 2 (November 2020), 45–52. https://doi.org/10.1145/3440968.3440974\nJon Kleinberg and Manish Raghavan. 2019. How Do Classifiers Induce Agents to Invest Effort Strategically? In Proceedings of the 2019 ACM Conference on Economics and Computation (EC ‘19). Association for Computing Machinery, New York, NY, USA, 825–844. https://doi.org/10.1145/3328526.3329584\n",
  "wordCount" : "592",
  "inLanguage": "en",
  "datePublished": "2024-06-04T23:47:17+08:00",
  "dateModified": "2024-06-04T23:47:17+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//localhost:1313/posts/network_principle_agent/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "ariana's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "//localhost:1313/favicon.ico"
    }
  }
}
</script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Product+Sans:wght@400;700&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="//localhost:1313/css/custom.b017fc6c61ff4eacd2943e3c9726e1a935c706d1ea1a1b7c17773e63b47342d3.css">
    
<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053">
</script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

<script>
  gtag('event', 'conversion', {
      'send_to': 'AW-16651897053/wjItCK3FisUZEN2Rn4Q-',
      'value': 1.0,
      'currency': 'USD'
  });
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/" accesskey="h" title="ariana&#39;s blog (Alt + H)">ariana&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/search" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/archives" title="archive">
                    <span>archive</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/tags" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/pinned" title="about me">
                    <span>about me</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/procrastination_bulletin" title="pending ideas">
                    <span>pending ideas</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      write-up | algorithmic classification and strategic effort
    </h1>
    <div class="post-meta"><span title='2024-06-04 23:47:17 +0800 CST'>June 4, 2024</span>

</div>
  </header>
  <div class="post-content"><p>A memoir of Market Mechanism Design course&rsquo;s final presentation report, based on:</p>
<blockquote>
<h3 id="algorithmic-classification-and-strategic-effort">Algorithmic Classification and Strategic Effort<a hidden class="anchor" aria-hidden="true" href="#algorithmic-classification-and-strategic-effort">#</a></h3>
<p>Jon Kleinberg and Manish Raghavan | ACM SIGecom Exchanges, Vol. 18, No. 2, November 2020, Pages 53–60</p>
</blockquote>
<h2 id="motivation-difference-in-modelling-strategic-behavior-and-objectivesbetween-econcs-perspectives">motivation: difference in modelling strategic behavior and objectives–between econ/CS perspectives<a hidden class="anchor" aria-hidden="true" href="#motivation-difference-in-modelling-strategic-behavior-and-objectivesbetween-econcs-perspectives">#</a></h2>
<blockquote>
<p>The principal-agent and strategic machine learning literatures appear to share a common goal: how should one structure a decision-making rule to account for the strategic actions of decision subjects?</p>
</blockquote>
<p>The paper proposes a model that applies ideas from principal-agent theory to the algorithmic decision-making setting.</p>
<blockquote>
<p>A key feature of models of strategic behavior in both the principal-agent and strategic classification literatures is that of hidden actions: decision-makers can’t observe the exact actions taken by a decision-subject.</p>
<p>In the principal-agent literature, this is typically captured through stochastic outcomes, where each action by the agent produces a distribution over possible outcomes, but only one outcome is realized and observed by the principal.</p>
<p>In the strategic classification literature, actions are typically not explicitly modeled; instead, a decision-maker simply observes a fea- ture vector, where the values of the feature vector can be strategically manipulated (to a limited degree) by the decision subject.</p>
</blockquote>
<h2 id="model">model<a hidden class="anchor" aria-hidden="true" href="#model">#</a></h2>
<p>The principle has <strong>preferences over the underlying behaviors</strong> taken by decision subjects. The model requires decisions (of principle) to be made based on observable feature vectors–that he structure his mechanism to incentivize agents take certain behaviors over others.</p>
<p>Algorithmic aspect comes in when the paper models the relationship between actions and observations as an <strong>effort graph</strong>, shown in below.</p>
<figure class="align-center ">
    <img loading="lazy" src="/who_do_we_blame/effort_graph.jpeg#center"
         alt="effort variables $x_1, \ldots, x_m$, which are the $m$ actions the agent can take. features $F_1, \ldots, F_n$ is the $n$-dimensional feature vector the decision maker actually observes."/> <figcaption>
            <p>effort variables $x_1, \ldots, x_m$, which are the $m$ actions the agent can take. features $F_1, \ldots, F_n$ is the $n$-dimensional feature vector the decision maker actually observes.</p>
        </figcaption>
</figure>

<p>In particular, each edge between $x_j$ and $F_i$ contains a parameter $\alpha_{ji}$ indicating the degree to which action $j$ increases feature $i$. Formally
$$
F_i = f_i \left (\sum_{j = 1}^m \alpha_{ij} x_j \right)
$$
where $f$ is some continuous concave function, and assumed that $\alpha \ge 0$. Basically, the larger $\alpha_{ij}$, the more extent of $x_j$ in increasing $F_i$.</p>
<p>Assume that the model&rsquo;s structure and parameters are public knowledge.</p>
<p>The mechanism designer (i.e. us, or the principle) designs a score function $H = M(\mathbf  F)$, and the agent reacts accordingly
$$
\begin{align}\text{agent&rsquo;s obj: }\max_x \ &amp; M(\mathbf F)\cr
s.t.\ &amp; \sum_{j = 1}^m x_j \le B  &amp; (\forall i)\cr
&amp; x_j \ge 0 &amp; (\forall j)
\end{align}
$$
As the designer, we are insterested in whether a particular action (i.e. effort invested) $x^* \in \mathbb{R}{}_{\ge 0}^m$ (or, its support $S(x^*)$) is incentivizable via some scoring rule design of $M(\cdot)$. The result is:</p>
<figure class="align-center ">
    <img loading="lazy" src="/who_do_we_blame/linear_incentives.jpeg#center"
         alt="linear mechanisms are optimal in the following sense: whenever a &lsquo;reasonable&rsquo; mechanism can incentivize a particular behavior, there is a linear mechanism that can do so as well."/> <figcaption>
            <p>linear mechanisms are optimal in the following sense: whenever a &lsquo;reasonable&rsquo; mechanism can incentivize a particular behavior, there is a linear mechanism that can do so as well.</p>
        </figcaption>
</figure>

<p>Moreover, let&rsquo;s say, we&rsquo;d like to optimize for a set of desirable actions $D\subset [m]$. Let $\mathcal X_D  = {x | S(x) \subset D}$ (i.e. the set of effort profiles that is only supported on $D$, that we wish to incentivize).
$$
\begin{align}\text{principle&rsquo;s obj: }\max_x \ &amp; g(x)
\quad
s.t.\ x \text{ is incentivizable}
\end{align}
$$
<figure class="align-center ">
    <img loading="lazy" src="/who_do_we_blame/linear_incentives_1.jpeg#center"
         alt="it can be hard to incentivize a complex set of behaviors while also optimizing other objectives."/> <figcaption>
            <p>it can be hard to incentivize a complex set of behaviors while also optimizing other objectives.</p>
        </figcaption>
</figure>
</p>
<h3 id="reference">reference<a hidden class="anchor" aria-hidden="true" href="#reference">#</a></h3>
<p>Jon Kleinberg and Manish Raghavan. 2020. Algorithmic classification and strategic effort. SIGecom Exch. 18, 2 (November 2020), 45–52. <a href="https://doi.org/10.1145/3440968.3440974">https://doi.org/10.1145/3440968.3440974</a></p>
<p>Jon Kleinberg and Manish Raghavan. 2019. How Do Classifiers Induce Agents to Invest Effort Strategically? In Proceedings of the 2019 ACM Conference on Economics and Computation (EC &lsquo;19). Association for Computing Machinery, New York, NY, USA, 825–844. <a href="https://doi.org/10.1145/3328526.3329584">https://doi.org/10.1145/3328526.3329584</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/tags/paper/">Paper</a></li>
      <li><a href="//localhost:1313/tags/tcs/">TCS</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:1313/">ariana&#39;s blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script id="usercentrics-cmp" src="https://web.cmp.usercentrics.eu/ui/loader.js" data-settings-id="_KlbvhaKistzRA" async></script>

</body>

</html>
