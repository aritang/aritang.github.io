<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>design of twitter&#39;s Birdwatch mechanism | ariana&#39;s blog</title>
<meta name="keywords" content="">
<meta name="description" content="Here&rsquo;s an interesting paper about crowdsourcing annotation of tweets. Given a twitter post containing possibly misleading information, the Birdwatch project aims to crowdsource comments on the OG tweet. One problem is to choose among the annotations one most credible annotation to display.

Birdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding and Reduce the Spread of Misinformation
Stefan Wojcik et al. Arxiv link.

Background
So, about Birdwatch:

     
            Birdwatch is Twitter&rsquo;s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets.">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/posts/birdwatch/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/posts/birdwatch/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>




<meta property="og:url" content="//localhost:1313/posts/birdwatch/">
  <meta property="og:site_name" content="ariana&#39;s blog">
  <meta property="og:title" content="design of twitter&#39;s Birdwatch mechanism">
  <meta property="og:description" content="Here’s an interesting paper about crowdsourcing annotation of tweets. Given a twitter post containing possibly misleading information, the Birdwatch project aims to crowdsource comments on the OG tweet. One problem is to choose among the annotations one most credible annotation to display.
Birdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding and Reduce the Spread of Misinformation Stefan Wojcik et al. Arxiv link.
Background So, about Birdwatch:
Birdwatch is Twitter’s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-01-22T20:43:29+08:00">
    <meta property="article:modified_time" content="2025-01-22T20:43:29+08:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="design of twitter&#39;s Birdwatch mechanism">
<meta name="twitter:description" content="Here&rsquo;s an interesting paper about crowdsourcing annotation of tweets. Given a twitter post containing possibly misleading information, the Birdwatch project aims to crowdsource comments on the OG tweet. One problem is to choose among the annotations one most credible annotation to display.

Birdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding and Reduce the Spread of Misinformation
Stefan Wojcik et al. Arxiv link.

Background
So, about Birdwatch:

     
            Birdwatch is Twitter&rsquo;s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "//localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "design of twitter's Birdwatch mechanism",
      "item": "//localhost:1313/posts/birdwatch/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "design of twitter's Birdwatch mechanism",
  "name": "design of twitter\u0027s Birdwatch mechanism",
  "description": "Here\u0026rsquo;s an interesting paper about crowdsourcing annotation of tweets. Given a twitter post containing possibly misleading information, the Birdwatch project aims to crowdsource comments on the OG tweet. One problem is to choose among the annotations one most credible annotation to display.\nBirdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding and Reduce the Spread of Misinformation Stefan Wojcik et al. Arxiv link.\nBackground So, about Birdwatch:\nBirdwatch is Twitter\u0026rsquo;s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets.\n",
  "keywords": [
    
  ],
  "articleBody": "Here’s an interesting paper about crowdsourcing annotation of tweets. Given a twitter post containing possibly misleading information, the Birdwatch project aims to crowdsource comments on the OG tweet. One problem is to choose among the annotations one most credible annotation to display.\nBirdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding and Reduce the Spread of Misinformation Stefan Wojcik et al. Arxiv link.\nBackground So, about Birdwatch:\nBirdwatch is Twitter’s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets.\nTo be exact, for a potentially problematic tweet, users may (i) write notes for the tweet or (ii) rate the notes’s helpfulnes. Then, for a single tweet, in place of multiple notes, there needs to be an algorithm to select one note to display to all users along with the tweet, as the informative ‘complement’ to the OG tweet.\nRemark: this Birdwatch note does NOT affect the recommendations of the OG tweet.\nThe problem comes to defining objective, or evaluating the algorithm’s outcome. So which such note would be an ideal recommendation? Especially in terms of highly polarized opinion battlefield like Twitter, this could be complicated:\nIdentifying notes that satisfy both aims is a challenge. For instance, some well-sourced notes may be seen as unhelpful because they are poorly written, or because they use language that may be perceived as biased or argumentative… Similarly, notes with weak sourcing, or without a strong factual basis, may appeal to people by invoking taken-for-granted ideas or assumptions…\nA core challenge for Birdwatch, then, is to identify notes which not only contain accurate, high quality information, but are also written in a way that is likely to resonate with broad audiences, not just those who are already inclined to agree.\nThe algorithm designed (termed as “matrix factorization (MF) algorithm”) balances interpretability and practicality:\nThe Algorithm The paper is written in Econ terminologies. How about a CS version? Here it is:\ninput user-note wise (sparse) rating matrix [$r_{u, n}$], where subscript $u$ denote user and $n$ note. Each rating $r_{u, n}$ takes three possible values: $0$ (not useful) $1$ (useful) or null (not rated).\nstep 1: fit an initial model Given this large zero-one sparse matrix as input, the algorithm basically first fit a model, assuming that each rating is powered by $$ \\hat r_{u, n} = \\mu + i_u+ i_n + f_u\\cdot f_n $$ ($\\mu$ is global intercept, $i_u, i_n$ are user/note’s specifc intercept. $f_u, f_n$ are feature vectors of user and notes whose product also contribute to rating outcomes (which, btw seems to be scalers).)\nTo estimate the parameters, the authors minimize the following regularized least squared error loss function via gradient descent over the dataset of all observed ratings $r_{u, n}$ :\nfrom the paper\nWhere, $\\lambda_i$ (0.15), the regularization on the intercept terms, is currently 5 times higher than $\\lambda_f$ (0.03), the regularization on the factors.\nAmong the fitted parameters, the note’s intercept—$i_n$—indicates a note’s independent value. The paper then assigns a first-stage-label to notes by $i_n$’s value:\n$0.4 \\le i_n$: helpful. $-0.08\\le i_n \\le 0.4$: needs more ratings. $i_n \\le -0.08$: not helpful. step 2: filter raters and note writers Filter raters:\nDefine Rater Helpfulness as the proportion of a rater’s “valid ratings” that match the note’s provisional label. Define Valid Ratings as ratings on notes provisionally labeled “helpful” and “not helpful” (excluding “needs more ratings”). Raters are discarded if their rater helpfulness is below 2/3.\nFilter note writers:\nif a user did author any notes that have received at least 5 ratings, that user must meet the following criteria for their ratings to be included:\nThe number of provisionally “helpful” notes written must be at least 5 times the number of “not helpful” notes written The average intercept of all notes they have written must be at least 0.05. Btw, this note-writer filter sounds like a heuristic reputation system to proof against chunk manipulation of note ratings.\nstep 3: Fit the same model (in step 1) again, but using the filtered raters and note writers’ notes. And use the newly fitted note’s intercept $i_n$ and the threshold (-0.08, 0.4) to classify (not-)helpfulness.\nEvaluation Users are sampled and recruited on the Twitter platform to conduct surveys.\nControl group: respondents were shown Tweets alone.\nTreatment group: Tweets plus annotations.\nEach respondent in the treatment and control groups was asked whether they thought the Tweet they saw was accurate, whether they agreed with a statement summarizing the main claim of the Tweet, and whether they agreed with a statement summarizing the main claim of the note.\nEvaluation group: Tweets plus annotations but a different questionnaire\nEach respondent in the evaluation group was asked whether they found the annotation to be helpful or unhelpful for understanding the issue discussed in the Tweet. Each of these key dependent variables is measured on a five-item ordinal scale, plus a “don’t know” option. Respondents were also free to skip any question.\nThe result section discussed evaluation of the algorithm’s outcome, and discussion around three questions:\nRQ1: Can we select a set of Birdwatch notes that both inform understanding (decrease propensity to agree with a potentially misleading claim) and are seen as helpful by a diverse population of users (in particular, users with diverse self-reported political affiliations)? Does algorithmic selection achieve these better than a supermajority voting baseline? RQ2: How closely related are appraisals of the accuracy of a Tweet and agreement with a Tweet’s claims? Can appraisals of the accuracy of a Tweet reliably be used as proxies for agreement with a Tweet’s claims? RQ3: Can crowd-generated Tweet annotations reduce the spreadof potentially misleading information on Twitter? Does exposure to Tweet annotations reduce retweeting and “Liking” behavior compared to users who do not see annotations? ",
  "wordCount" : "953",
  "inLanguage": "en",
  "datePublished": "2025-01-22T20:43:29+08:00",
  "dateModified": "2025-01-22T20:43:29+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//localhost:1313/posts/birdwatch/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "ariana's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "//localhost:1313/favicon.ico"
    }
  }
}
</script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Product+Sans:wght@400;700&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="//localhost:1313/css/custom.b017fc6c61ff4eacd2943e3c9726e1a935c706d1ea1a1b7c17773e63b47342d3.css">
    
<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053">
</script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

<script>
  gtag('event', 'conversion', {
      'send_to': 'AW-16651897053/wjItCK3FisUZEN2Rn4Q-',
      'value': 1.0,
      'currency': 'USD'
  });
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/" accesskey="h" title="ariana&#39;s blog (Alt + H)">ariana&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/search" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/archives" title="archive">
                    <span>archive</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/tags" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/pinned" title="about me">
                    <span>about me</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/procrastination_bulletin" title="pending ideas">
                    <span>pending ideas</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      design of twitter&#39;s Birdwatch mechanism
    </h1>
    <div class="post-meta"><span title='2025-01-22 20:43:29 +0800 +0800'>January 22, 2025</span>

</div>
  </header>
  <div class="post-content"><p>Here&rsquo;s an interesting paper about crowdsourcing annotation of tweets. Given a twitter post containing possibly misleading information, the <em><strong>Birdwatch</strong></em> project aims to crowdsource comments on the OG tweet. One problem is to choose among the annotations <em><strong>one</strong></em> most credible annotation to display.</p>
<blockquote>
<h3 id="birdwatch-crowd-wisdom-and-bridging-algorithms-can-inform-understanding-and-reduce-the-spread-of-misinformation">Birdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding and Reduce the Spread of Misinformation<a hidden class="anchor" aria-hidden="true" href="#birdwatch-crowd-wisdom-and-bridging-algorithms-can-inform-understanding-and-reduce-the-spread-of-misinformation">#</a></h3>
<p>Stefan Wojcik et al. <a href="https://arxiv.org/abs/2210.15723">Arxiv link.</a></p>
</blockquote>
<h2 id="background">Background<a hidden class="anchor" aria-hidden="true" href="#background">#</a></h2>
<p>So, about Birdwatch:</p>
<figure class="align-center ">
    <img loading="lazy" src="/google_ad_gossip/twitter_birdwatch.jpeg#center"
         alt="Birdwatch is Twitter&rsquo;s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets." width="66%"/> <figcaption>
            <p>Birdwatch is Twitter&rsquo;s community-driven approach to identify misinformation. It encourages users add informative clarification notes to Tweets.</p>
        </figcaption>
</figure>

<p>To be exact, for a potentially problematic tweet, users may (i) write <em><strong>notes</strong></em> for the tweet or (ii) rate the <em><strong>notes</strong></em>&rsquo;s helpfulnes. Then, for a single tweet, in place of multiple notes, there needs to be an algorithm to select one note to display to all users along with the tweet, as the informative &lsquo;complement&rsquo; to the OG tweet.</p>
<p>Remark: this Birdwatch note does NOT affect the recommendations of the OG tweet.</p>
<p>The problem comes to defining objective, or evaluating the algorithm&rsquo;s outcome. So which such note would be an ideal recommendation? Especially in terms of highly polarized opinion battlefield like Twitter, this could be complicated:</p>
<blockquote>
<p>Identifying notes that satisfy both aims is a challenge. For instance, some well-sourced notes may be seen as unhelpful because they are poorly written, or because they use language that may be perceived as biased or argumentative&hellip; Similarly, notes with weak sourcing, or without a strong factual basis, may appeal to people by invoking taken-for-granted ideas or assumptions&hellip;</p>
<p><strong>A core challenge for Birdwatch, then, is to identify notes which not only contain accurate, high quality information, but are also written in a way that is likely to resonate with broad audiences, not just those who are already inclined to agree.</strong></p>
</blockquote>
<p>The algorithm designed (termed as &ldquo;matrix factorization (MF) algorithm&rdquo;) balances interpretability and practicality:</p>
<h2 id="the-algorithm">The Algorithm<a hidden class="anchor" aria-hidden="true" href="#the-algorithm">#</a></h2>
<p>The paper is written in Econ terminologies. How about a CS version? Here it is:</p>
<h3 id="input">input<a hidden class="anchor" aria-hidden="true" href="#input">#</a></h3>
<blockquote>
<p>user-<em><strong>note</strong></em> wise (sparse) rating matrix [$r_{u, n}$], where subscript $u$ denote user and $n$ note. Each rating $r_{u, n}$ takes three possible values: $0$ (not useful) $1$ (useful) or null (not rated).</p>
</blockquote>
<h3 id="step-1-fit-an-initial-model">step 1: fit an initial model<a hidden class="anchor" aria-hidden="true" href="#step-1-fit-an-initial-model">#</a></h3>
<p>Given this large zero-one sparse matrix as input, the algorithm basically first fit a model, assuming that each rating is powered by
$$
\hat r_{u, n} = \mu + i_u+ i_n + f_u\cdot f_n
$$
($\mu$ is global intercept, $i_u, i_n$ are user/note&rsquo;s specifc intercept. $f_u, f_n$ are feature vectors of user and notes whose product also contribute to rating outcomes (which, btw seems to be scalers).)</p>
<blockquote>
<p>To estimate the parameters, the authors minimize the following regularized least squared error loss function via gradient descent over the dataset of all observed ratings $r_{u, n}$ :</p>
<figure class="align-center ">
    <img loading="lazy" src="/google_ad_gossip/birdwatch_function1.jpeg#center"
         alt="from the paper" width="100%"/> <figcaption>
            <p>from the paper</p>
        </figcaption>
</figure>

<p>Where, $\lambda_i$ (0.15), the regularization on the intercept terms, is currently 5 times higher than $\lambda_f$ (0.03), the regularization on the factors.</p>
</blockquote>
<p>Among the fitted parameters, the note&rsquo;s intercept—$i_n$—indicates a note&rsquo;s independent value. The paper then assigns a first-stage-label to notes by $i_n$&rsquo;s value:</p>
<ul>
<li>$0.4 \le i_n$: helpful.</li>
<li>$-0.08\le i_n \le 0.4$: needs more ratings.</li>
<li>$i_n \le -0.08$: not helpful.</li>
</ul>
<h3 id="step-2-filter-raters-and-note-writers">step 2: filter raters and note writers<a hidden class="anchor" aria-hidden="true" href="#step-2-filter-raters-and-note-writers">#</a></h3>
<ul>
<li>
<p>Filter raters:</p>
<ul>
<li>Define <em>Rater Helpfulness</em> as the proportion of a rater’s “valid ratings” that match the note’s provisional label.</li>
<li>Define <em>Valid Ratings</em> as ratings on notes provisionally labeled “helpful” and “not helpful” (excluding &ldquo;needs more ratings&rdquo;).</li>
</ul>
<p>Raters are discarded if their rater helpfulness is below 2/3.</p>
</li>
<li>
<p>Filter note writers:</p>
<blockquote>
<p>if a user did author any notes that have received at least 5 ratings, that user must meet the following criteria for their ratings to be included:</p>
<ul>
<li>The number of provisionally “helpful” notes written must be at least 5 times the number of “not helpful” notes written</li>
<li>The average intercept of all notes they have written must be at least 0.05.</li>
</ul>
</blockquote>
<p>Btw, this note-writer filter sounds like a heuristic reputation system to proof against chunk manipulation of note ratings.</p>
</li>
</ul>
<h3 id="step-3">step 3:<a hidden class="anchor" aria-hidden="true" href="#step-3">#</a></h3>
<p>Fit the same model (in step 1) again, but using the filtered raters and note writers&rsquo; notes. And use the newly fitted note&rsquo;s intercept $i_n$ and the threshold (-0.08, 0.4) to classify (not-)helpfulness.</p>
<h3 id="evaluation">Evaluation<a hidden class="anchor" aria-hidden="true" href="#evaluation">#</a></h3>
<p>Users are sampled and recruited on the Twitter platform to conduct surveys.</p>
<ul>
<li>
<p>Control group: respondents were shown Tweets alone.</p>
</li>
<li>
<p>Treatment group: Tweets plus annotations.</p>
<blockquote>
<p>Each respondent in the treatment and control groups was asked whether they thought the Tweet they saw was accurate, whether they agreed with a statement summarizing the main claim of the Tweet, and whether they agreed with a statement summarizing the main claim of the note.</p>
</blockquote>
</li>
<li>
<p>Evaluation group: Tweets plus annotations but a different questionnaire</p>
<blockquote>
<p>Each respondent in the evaluation group was asked whether they found the annotation to be helpful or unhelpful for understanding the issue discussed in the Tweet. Each of these key dependent variables is measured on a five-item ordinal scale, plus a “don’t know” option. Respondents were also free to skip any question.</p>
</blockquote>
</li>
</ul>
<p>The result section discussed evaluation of the algorithm&rsquo;s outcome, and discussion around three questions:</p>
<ul>
<li>RQ1: Can we select a set of Birdwatch notes that both inform understanding (decrease propensity to agree with a potentially misleading claim) and are seen as helpful by a diverse population of users (in particular, users with diverse self-reported political affiliations)? Does algorithmic selection achieve these better than a supermajority voting baseline?</li>
<li>RQ2: How closely related are appraisals of the accuracy of a Tweet and agreement with a Tweet’s claims? Can appraisals of the accuracy of a Tweet reliably be used as proxies for agreement with a Tweet’s claims?</li>
<li>RQ3: Can crowd-generated Tweet annotations reduce the spreadof potentially misleading information on Twitter? Does exposure to Tweet annotations reduce retweeting and &ldquo;Liking&rdquo; behavior compared to users who do not see annotations?</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:1313/">ariana&#39;s blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script id="usercentrics-cmp" src="https://web.cmp.usercentrics.eu/ui/loader.js" data-settings-id="_KlbvhaKistzRA" async></script>

</body>

</html>
