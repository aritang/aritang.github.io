<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>game theory, with a little help from machine learning I | ariana&#39;s blog</title>
<meta name="keywords" content="paper, TCS">
<meta name="description" content="Of course, the general purpose of an academic presentation is multifaceted (see an older post about it), as discussed here. Nevertheless, I&rsquo;ve once heard someone say that the key purpose of a talk at a conference is to make your audience interested in reading your work after the talk ends.
I attended the RAIN seminar yesterday at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan&rsquo;s talk was particularly captivating. So, I decided to read a bit of the paper, Online Learning in Stackelberg Security Games :">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/posts/rain_seminar_1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/posts/rain_seminar_1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>




<meta property="og:url" content="//localhost:1313/posts/rain_seminar_1/">
  <meta property="og:site_name" content="ariana&#39;s blog">
  <meta property="og:title" content="game theory, with a little help from machine learning I">
  <meta property="og:description" content="Of course, the general purpose of an academic presentation is multifaceted (see an older post about it), as discussed here. Nevertheless, I’ve once heard someone say that the key purpose of a talk at a conference is to make your audience interested in reading your work after the talk ends.
I attended the RAIN seminar yesterday at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan’s talk was particularly captivating. So, I decided to read a bit of the paper, Online Learning in Stackelberg Security Games :">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-26T07:26:22-07:00">
    <meta property="article:modified_time" content="2024-06-26T07:26:22-07:00">
    <meta property="article:tag" content="Paper">
    <meta property="article:tag" content="TCS">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="game theory, with a little help from machine learning I">
<meta name="twitter:description" content="Of course, the general purpose of an academic presentation is multifaceted (see an older post about it), as discussed here. Nevertheless, I&rsquo;ve once heard someone say that the key purpose of a talk at a conference is to make your audience interested in reading your work after the talk ends.
I attended the RAIN seminar yesterday at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan&rsquo;s talk was particularly captivating. So, I decided to read a bit of the paper, Online Learning in Stackelberg Security Games :">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "//localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "game theory, with a little help from machine learning I",
      "item": "//localhost:1313/posts/rain_seminar_1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "game theory, with a little help from machine learning I",
  "name": "game theory, with a little help from machine learning I",
  "description": "Of course, the general purpose of an academic presentation is multifaceted (see an older post about it), as discussed here. Nevertheless, I\u0026rsquo;ve once heard someone say that the key purpose of a talk at a conference is to make your audience interested in reading your work after the talk ends.\nI attended the RAIN seminar yesterday at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan\u0026rsquo;s talk was particularly captivating. So, I decided to read a bit of the paper, Online Learning in Stackelberg Security Games :\n",
  "keywords": [
    "paper", "TCS"
  ],
  "articleBody": "Of course, the general purpose of an academic presentation is multifaceted (see an older post about it), as discussed here. Nevertheless, I’ve once heard someone say that the key purpose of a talk at a conference is to make your audience interested in reading your work after the talk ends.\nI attended the RAIN seminar yesterday at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan’s talk was particularly captivating. So, I decided to read a bit of the paper, Online Learning in Stackelberg Security Games :\nRegret Minimization in Stackelberg Games with Side Information Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | paper’s arxiv link\nthe game A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a defensive strategy, and the attacker responds by choosing a target to attack. The outcome for both parties depends on their chosen actions and potentially some unknown world state.\nThere are $i = 1, 2, \\ldots, n$ possible targets. The defender has one unit of defensive effort to allocate among these targets, represented by a strategy vector: $$ \\mathbf p = [p_1, p_2, \\ldots, p_n] $$ where $ \\sum_i p_i = 1 $ and $ p_i \\in [0, 1] $. At every time point, after the defender chooses $\\mathbf p$, an attacker comes, knowing $\\mathcal p$, chooses a target $ i^* $ that maximizes his utility: $$ \\text{(attacker’s utility) } U^\\text a = \\max_{\\mathbf y} \\sum_{i\\in [n]}y_i\\left( p_iu^1_i + (1 - p_i)u^0_i\\right)\\ \\text{later we’ll see, it’s type-dependent} $$ Here, $ u_i^1 $ and $ u_i^0 $ are the attacker’s utilities from attacking target $i$ when it is protected and unprotected, respectively. The attacker’s action vector $ \\mathbf y \\in {0, 1}^n $. The optimal attack response to the defender’s strategy $ \\mathbf p $ is: $$ \\mathbf y^:=\\arg\\max_{\\mathbf y}\\sum_{i\\in [n]}y_i\\left( p_iu^1_i + (1 - p_i)u^0_i\\right) $$ Given the attacker’s best response $ \\mathbf y^(\\mathbf p) $, the defender’s utility is: $$ \\text{(defender’s utility) } U^\\text d (\\mathbf p) = \\sum_{i \\in [n]} \\left( y^_i (v^1_i p_i + v^0_i (1 - p_i)) + (1 - y^_i)(\\bar v_i^1 p_i + \\bar v_i (1 - p_i)) \\right) $$ From my memory of the talk, the model is linear in both players’ strategies. However, the paper uses more general notations and definitions, but the results rely heavily on a polytope-linear partition of the defender’s action space, so the linear assumption should be quite general.\nno-regret Taking the defender’s perspective in a dynamic setting, at each time point $ t = 1, 2, \\ldots, T $, nature selects an attacker $ A_{k_t} $ from a set of $ K $ possible attackers, with different utility functions and attacking habits. The defender knows the utilities but not the upcoming attacker’s type before committing to a strategy $ \\mathbf p^t $.\nThe regret is defined as: $$ \\text{(regret) }R(T) = \\tilde U^d(\\mathbf {\\tilde {p^t}})-\\sum_{t = 1}^T U^d(\\mathbf p^t) $$ where $ \\tilde U^d $ is the optimal-in-hindsight benchmark.\nNo-regret benchmark:\nThe optimal-in-hindsight benchmark $\\tilde U^d$ is defined for optimized strategy knowning the upcoming chosen sequence ${A_{k_1}, \\ldots, A_{k_T}}$. But, the attacker’s action at each time point still changes given the defender’s strategy changes.\nWhen the set of attackers is fixed and finite, no-regret learning (where $ R(T) = o(T) $) is achievable. The paper explores introducing context into this dynamic decision-making environment.\nIt’s late tonight. Stay tuned for tomorrow, where I’ll write more about the modeling approach and its implications.\n",
  "wordCount" : "599",
  "inLanguage": "en",
  "datePublished": "2024-06-26T07:26:22-07:00",
  "dateModified": "2024-06-26T07:26:22-07:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//localhost:1313/posts/rain_seminar_1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "ariana's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "//localhost:1313/favicon.ico"
    }
  }
}
</script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Product+Sans:wght@400;700&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="//localhost:1313/css/custom.b017fc6c61ff4eacd2943e3c9726e1a935c706d1ea1a1b7c17773e63b47342d3.css">
    
<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053">
</script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

<script>
  gtag('event', 'conversion', {
      'send_to': 'AW-16651897053/wjItCK3FisUZEN2Rn4Q-',
      'value': 1.0,
      'currency': 'USD'
  });
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=AW-16651897053"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'AW-16651897053');
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/" accesskey="h" title="ariana&#39;s blog (Alt + H)">ariana&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/search" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/archives" title="archive">
                    <span>archive</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/tags" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/posts/pinned" title="about me">
                    <span>about me</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/procrastination_bulletin" title="pending ideas">
                    <span>pending ideas</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      game theory, with a little help from machine learning I
    </h1>
    <div class="post-meta"><span title='2024-06-26 07:26:22 -0700 -0700'>June 26, 2024</span>

</div>
  </header>
  <div class="post-content"><p>Of course, the general purpose of an academic presentation is multifaceted (see an <a href="/posts/idea_of_a_presentation/">older post</a> about it), as discussed here. Nevertheless, I&rsquo;ve once heard someone say that the key purpose of a talk at a conference is to <strong>make your audience interested in reading your work after the talk ends</strong>.</p>
<p>I attended the RAIN seminar <a href="posts/rain_seminar/">yesterday</a> at Y2E2, Stanford, where Nina Balcan presented one of her latest works. Personally, I have a general interest in research that involves complex human behaviors. But Nina Balcan&rsquo;s talk was particularly captivating. So, I decided to read a bit of the paper, <em>Online Learning in Stackelberg Security Games</em> :</p>
<blockquote>
<h2 id="regret-minimization-in-stackelberg-games-with-side-information">Regret Minimization in Stackelberg Games with Side Information<a hidden class="anchor" aria-hidden="true" href="#regret-minimization-in-stackelberg-games-with-side-information">#</a></h2>
<p>Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan (2024) | <a href="https://arxiv.org/abs/2402.08576">paper&rsquo;s arxiv link</a></p>
</blockquote>
<h3 id="the-game">the game<a hidden class="anchor" aria-hidden="true" href="#the-game">#</a></h3>
<p>A Stackelberg Security Game is a structured competitive setting involving a defender and an attacker. The defender commits to a defensive strategy, and the attacker responds by choosing a target to attack. The outcome for both parties depends on their chosen actions and potentially some unknown world state.</p>
<p>There are $i = 1, 2, \ldots, n$ possible targets. The defender has one unit of defensive effort to allocate among these targets, represented by a strategy vector:
$$
\mathbf p = [p_1, p_2, \ldots, p_n]
$$
where $ \sum_i p_i = 1 $ and $ p_i \in [0, 1] $. At every time point, after the defender chooses $\mathbf p$, an attacker comes, knowing $\mathcal p$, chooses a target $ i^* $ that maximizes his utility:
$$
\text{(attacker&rsquo;s utility) } U^\text a =  \max_{\mathbf y} \sum_{i\in [n]}y_i\left(  p_iu^1_i + (1 - p_i)u^0_i\right)\
\text{later we&rsquo;ll see, it&rsquo;s type-dependent}
$$
Here, $ u_i^1 $ and $ u_i^0 $ are the attacker&rsquo;s utilities from attacking target $i$ when it is protected and unprotected, respectively. The attacker&rsquo;s action vector $ \mathbf y \in {0, 1}^n $. The optimal attack response to the defender&rsquo;s strategy $ \mathbf p $ is:
$$
\mathbf y^<em>:=\arg\max_{\mathbf y}\sum_{i\in [n]}y_i\left(  p_iu^1_i + (1 - p_i)u^0_i\right)
$$
Given the attacker&rsquo;s best response $ \mathbf y^</em>(\mathbf p) $, the defender&rsquo;s utility is:
$$
\text{(defender&rsquo;s utility) } U^\text d (\mathbf p) =  \sum_{i \in [n]} \left( y^<em>_i (v^1_i p_i + v^0_i (1 - p_i)) + (1 - y^</em>_i)(\bar v_i^1 p_i + \bar v_i (1 - p_i)) \right)
$$
From my memory of the talk, the model is linear in both players&rsquo; strategies. However, the paper uses more general notations and definitions, but the results rely heavily on a polytope-linear partition of the defender&rsquo;s action space, so the linear assumption should be quite general.</p>
<h3 id="no-regret">no-regret<a hidden class="anchor" aria-hidden="true" href="#no-regret">#</a></h3>
<p>Taking the defender&rsquo;s perspective in a dynamic setting, at each time point $ t = 1, 2, \ldots, T $, nature selects an attacker $ A_{k_t} $ from a set of $ K $ possible attackers, with different utility functions and attacking habits. The defender knows the utilities but not the upcoming attacker&rsquo;s type before committing to a strategy $ \mathbf p^t $.</p>
<p>The regret is defined as:
$$
\text{(regret) }R(T) =  \tilde U^d(\mathbf {\tilde {p^t}})-\sum_{t = 1}^T U^d(\mathbf p^t)
$$
where $ \tilde U^d $ is the optimal-in-hindsight benchmark.</p>
<blockquote>
<p>No-regret benchmark:</p>
<p>The optimal-in-hindsight benchmark $\tilde U^d$ is defined for optimized strategy <strong>knowning the upcoming chosen sequence ${A_{k_1}, \ldots, A_{k_T}}$</strong>. But, the attacker&rsquo;s action at each time point still changes given the defender&rsquo;s strategy changes.</p>
</blockquote>
<p>When the set of attackers is fixed and finite, no-regret learning (where $ R(T) = o(T) $) is achievable. The paper explores introducing context into this dynamic decision-making environment.</p>
<p>It&rsquo;s late tonight. Stay tuned for tomorrow, where I&rsquo;ll write more about the modeling approach and its implications.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/tags/paper/">Paper</a></li>
      <li><a href="//localhost:1313/tags/tcs/">TCS</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:1313/">ariana&#39;s blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script id="usercentrics-cmp" src="https://web.cmp.usercentrics.eu/ui/loader.js" data-settings-id="_KlbvhaKistzRA" async></script>

</body>

</html>
